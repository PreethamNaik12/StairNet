{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ffc8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install smart_open boto3 pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b0833dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists in /home/ec2-user/SageMaker/data/images. Skipping download and extraction.\n",
      "Data check complete. Images are available in /home/ec2-user/SageMaker/data/images\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from smart_open import open\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Set up the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define the S3 bucket and key\n",
    "bucket_name = 'ieee-dataport'\n",
    "object_key = 'data/7540/StairNet.zip'\n",
    "\n",
    "# Define the directory to save images\n",
    "local_image_dir = os.path.expanduser('~/SageMaker/data/images')\n",
    "\n",
    "# Function to check if data already exists\n",
    "def data_exists(local_dir):\n",
    "    # Check for the presence of any image files in the directory\n",
    "    images = glob.glob(os.path.join(local_dir, '*'))\n",
    "    if images:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Function to stream and extract images\n",
    "def stream_and_extract_images(bucket, key, local_dir):\n",
    "    buffer_size = 10 * 1024 * 1024  # 10 MB buffer size for reading chunks\n",
    "\n",
    "    # Use smart_open to stream the zip file\n",
    "    with open(f's3://{bucket}/{key}', 'rb') as s3_file:\n",
    "        # BufferedReader with a buffer size\n",
    "        with zipfile.ZipFile(io.BufferedReader(s3_file, buffer_size=buffer_size)) as z:\n",
    "            # Iterate over the files in the zip\n",
    "            for file_info in z.infolist():\n",
    "                if file_info.filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    try:\n",
    "                        with z.open(file_info) as image_file:\n",
    "                            img_save_path = os.path.join(local_dir, os.path.basename(file_info.filename))\n",
    "                            # Save only if the file doesn't exist\n",
    "                            if not os.path.exists(img_save_path):\n",
    "                                print(f\"Extracting {file_info.filename}...\")\n",
    "                                with open(img_save_path, 'wb') as f:\n",
    "                                    f.write(image_file.read())\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to extract {file_info.filename}: {e}\")\n",
    "\n",
    "# Create the local directory if it does not exist\n",
    "os.makedirs(local_image_dir, exist_ok=True)\n",
    "\n",
    "# Check if the data already exists\n",
    "if data_exists(local_image_dir):\n",
    "    print(f\"Data already exists in {local_image_dir}. Skipping download and extraction.\")\n",
    "else:\n",
    "    print(f\"Data does not exist in {local_image_dir}. Downloading and extracting...\")\n",
    "    # Stream and extract images\n",
    "    stream_and_extract_images(bucket_name, object_key, local_image_dir)\n",
    "\n",
    "print(f\"Data check complete. Images are available in {local_image_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76a080ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images ending with 'LG': 442360\n",
      "Number of images ending with 'LG-IS': 15888\n",
      "Number of images ending with 'IS': 48179\n",
      "Number of images ending with 'IS-LG': 9025\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory containing the images\n",
    "image_directory = '/home/ec2-user/SageMaker/data/images'\n",
    "\n",
    "# Initialize counters for each suffix\n",
    "lg_count = 0\n",
    "lg_is_count = 0\n",
    "is_count = 0\n",
    "is_lg_count = 0\n",
    "\n",
    "# List all files in the directory\n",
    "for filename in os.listdir(image_directory):\n",
    "    # Check and count for each suffix\n",
    "    if filename.endswith(' LG.jpg'):\n",
    "        lg_count += 1\n",
    "    elif filename.endswith(' LGIS.jpg'):\n",
    "        lg_is_count += 1\n",
    "    elif filename.endswith(' IS.jpg'):\n",
    "        is_count += 1\n",
    "    elif filename.endswith(' ISLG.jpg'):\n",
    "        is_lg_count += 1\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Number of images ending with 'LG': {lg_count}\")\n",
    "print(f\"Number of images ending with 'LG-IS': {lg_is_count}\")\n",
    "print(f\"Number of images ending with 'IS': {is_count}\")\n",
    "print(f\"Number of images ending with 'IS-LG': {is_lg_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07d75cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms, datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Rest of your code will go here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e083e44",
   "metadata": {},
   "source": [
    "## Step 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57725836",
   "metadata": {},
   "source": [
    "- First, let's define the dataset structure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb120e9",
   "metadata": {},
   "source": [
    "dataset_structure = {\n",
    "    'IS': 48179,\n",
    "    'ISLG': 9025,\n",
    "    'LG': 442360,\n",
    "    'LGIS': 15888\n",
    "}\n",
    "\n",
    "total_samples = sum(dataset_structure.values())\n",
    "print(f\"Total samples: {total_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe8c403",
   "metadata": {},
   "source": [
    "- Now, let's create functions to split the data according to the given percentages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a01f15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_dataset(dataset_structure, train_pct=0.895, val_pct=0.035, test_pct=0.07):\n",
    "#     train_set, val_set, test_set = {}, {}, {}\n",
    "    \n",
    "#     for class_name, total_samples in dataset_structure.items():\n",
    "#         train_samples = int(total_samples * train_pct)\n",
    "#         val_samples = int(total_samples * val_pct)\n",
    "#         test_samples = total_samples - train_samples - val_samples\n",
    "        \n",
    "#         train_set[class_name] = train_samples\n",
    "#         val_set[class_name] = val_samples\n",
    "#         test_set[class_name] = test_samples\n",
    "    \n",
    "#     return train_set, val_set, test_set\n",
    "\n",
    "# train_set, val_set, test_set = split_dataset(dataset_structure)\n",
    "\n",
    "# print(\"Training set:\", train_set)\n",
    "# print(\"Validation set:\", val_set)\n",
    "# print(\"Test set:\", test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1ec6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split_data(file_list, train_pct=0.895, val_pct=0.035, test_pct=0.07):\n",
    "    random.shuffle(file_list)\n",
    "    total = len(file_list)\n",
    "    train_end = int(total * train_pct)\n",
    "    val_end = train_end + int(total * val_pct)\n",
    "    \n",
    "    return file_list[:train_end], file_list[train_end:val_end], file_list[val_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e5ed43",
   "metadata": {},
   "source": [
    "- For loading the data, we'll need to create a custom dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1ca17a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class StairNetDataset(Dataset):\n",
    "    def __init__(self, root_dir, file_list, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = {'IS': 0, 'ISLG': 1, 'LG': 2, 'LGIS': 3}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.file_list[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Extract label from filename\n",
    "        parts = img_name.split()\n",
    "        label = parts[-1].split('.')[0]  # Get the last part before the file extension\n",
    "        \n",
    "        # Handle the case where the label might be two words (e.g., 'LG IS')\n",
    "        if len(parts) > 2 and parts[-2] in ['LG', 'IS']:\n",
    "            label = f\"{parts[-2]} {label}\"\n",
    "        \n",
    "        label_idx = self.class_to_idx[label]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddb6b90",
   "metadata": {},
   "source": [
    "- creat a stratified dataset\n",
    "- setup the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33a9fb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 461328\n",
      "Number of validation samples: 18039\n",
      "Number of test samples: 36085\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def split_data_stratified(file_list, train_pct=0.895, val_pct=0.035, test_pct=0.07):\n",
    "    # Group files by class\n",
    "    class_files = defaultdict(list)\n",
    "    for file in file_list:\n",
    "        parts = file.split()\n",
    "        label = parts[-1].split('.')[0]\n",
    "        if len(parts) > 2 and parts[-2] in ['LG', 'IS']:\n",
    "            label = f\"{parts[-2]} {label}\"\n",
    "        class_files[label].append(file)\n",
    "    \n",
    "    train_files, val_files, test_files = [], [], []\n",
    "    \n",
    "    for class_label, files in class_files.items():\n",
    "        random.shuffle(files)\n",
    "        n_files = len(files)\n",
    "        n_train = int(n_files * train_pct)\n",
    "        n_val = int(n_files * val_pct)\n",
    "        \n",
    "        train_files.extend(files[:n_train])\n",
    "        val_files.extend(files[n_train:n_train+n_val])\n",
    "        test_files.extend(files[n_train+n_val:])\n",
    "    \n",
    "    random.shuffle(train_files)\n",
    "    random.shuffle(val_files)\n",
    "    random.shuffle(test_files)\n",
    "    \n",
    "    return train_files, val_files, test_files\n",
    "\n",
    "# Define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Set up data\n",
    "root_dir = '/home/ec2-user/SageMaker/data/images'  \n",
    "all_files = os.listdir(root_dir)\n",
    "image_files = [f for f in all_files if f.endswith('.jpg')]\n",
    "\n",
    "# Split data\n",
    "train_files, val_files, test_files = split_data_stratified(image_files)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = StairNetDataset(root_dir, train_files, transform=train_transform)\n",
    "val_dataset = StairNetDataset(root_dir, val_files, transform=val_transform)\n",
    "test_dataset = StairNetDataset(root_dir, test_files, transform=val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3353ef5",
   "metadata": {},
   "source": [
    "- check the distribution (caution: takes very very long time to count! so run this if you have a lot of time availale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5643427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print class distribution in each split\n",
    "\n",
    "# def print_class_distribution(dataset):\n",
    "#     class_counts = defaultdict(int)\n",
    "#     for _, label in dataset:\n",
    "#         class_counts[label] += 1\n",
    "#     total = sum(class_counts.values())\n",
    "#     for label, count in class_counts.items():\n",
    "#         print(f\"Class {label}: {count} ({count/total:.2%})\")\n",
    "\n",
    "# print(\"\\nTraining set class distribution:\")\n",
    "# print_class_distribution(train_dataset)\n",
    "# print(\"\\nValidation set class distribution:\")\n",
    "# print_class_distribution(val_dataset)\n",
    "# print(\"\\nTest set class distribution:\")\n",
    "# print_class_distribution(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c32de1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
